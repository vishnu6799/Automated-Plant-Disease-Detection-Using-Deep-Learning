# -*- coding: utf-8 -*-
"""Final project 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1egJxsWS-nH8cKkAGuRLNeT7_xRMyeOjM
"""

import zipfile
import os

# Path to uploaded zip
zip_path = "/content/archive (40).zip"

# Extract to current directory
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("unzipped_data")

# Check extracted files
os.listdir("unzipped_data")

def count_images_in_folder(path):
    total = 0
    for root, dirs, files in os.walk(path):
        total += sum(1 for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg')))
    return total

print("PlantVillage:", len(os.listdir("unzipped_data/PlantVillage")),
      "subfolders,", count_images_in_folder("unzipped_data/PlantVillage"), "images")

print("plantvillage:", len(os.listdir("unzipped_data/plantvillage")),
      "subfolders,", count_images_in_folder("unzipped_data/plantvillage"), "images")

import shutil

# Remove the duplicate folder
shutil.rmtree("unzipped_data/plantvillage")

# Check remaining structure
os.listdir("unzipped_data")

import random
SRC_ROOT = "unzipped_data/PlantVillage"   # the class-folder version
DUPLICATE = "unzipped_data/plantvillage"  # the duplicate you said exists
DEST_ROOT = "data"                        # will contain train/val/test
TRAIN_PCT = 0.70
VAL_PCT = 0.15
TEST_PCT = 0.15
SEED = 42
IMG_EXTS = (".jpg", ".jpeg", ".png", ".bmp")

random.seed(SEED)

def remove_duplicate_if_redundant(dup_path, main_path):
    """If duplicate folder contains raw files in one folder, remove it (optional)."""
    if not os.path.exists(dup_path):
        print("No duplicate folder found:", dup_path)
        return
    # If duplicate is just one folder containing all images and main has properly split classes,
    # we can safely remove duplicate to free space.
    print(f"Removing duplicate folder {dup_path} (you said it is redundant).")
    shutil.rmtree(dup_path)

def split_dataset(src_root, dest_root, train_pct, val_pct, test_pct):
    assert abs(train_pct + val_pct + test_pct - 1.0) < 1e-6
    os.makedirs(dest_root, exist_ok=True)
    splits = ["train", "val", "test"]
    for s in splits:
        os.makedirs(os.path.join(dest_root, s), exist_ok=True)

    classes = sorted([d for d in os.listdir(src_root) if os.path.isdir(os.path.join(src_root, d))])
    print(f"Found {len(classes)} classes: {classes[:10]} ...")

    for cls in classes:
        cls_src = os.path.join(src_root, cls)
        images = [f for f in os.listdir(cls_src) if f.lower().endswith(IMG_EXTS)]
        random.shuffle(images)
        n = len(images)
        n_train = int(n * train_pct)
        n_val = int(n * val_pct)
        # rest goes to test
        train_files = images[:n_train]
        val_files = images[n_train:n_train + n_val]
        test_files = images[n_train + n_val:]

        for split_name, file_list in zip(splits, [train_files, val_files, test_files]):
            cls_dest = os.path.join(dest_root, split_name, cls)
            os.makedirs(cls_dest, exist_ok=True)
            for filename in file_list:
                src_f = os.path.join(cls_src, filename)
                dst_f = os.path.join(cls_dest, filename)
                # copy (keeps original dataset intact). If disk is tight, use move() instead
                shutil.copy2(src_f, dst_f)

        print(f"{cls}: total={n}, train={len(train_files)}, val={len(val_files)}, test={len(test_files)}")

if __name__ == "__main__":
    # Optional: remove duplicate folder (you confirmed it's redundant)
    remove_duplicate_if_redundant(DUPLICATE, SRC_ROOT)

    # Split the dataset
    split_dataset(SRC_ROOT, DEST_ROOT, TRAIN_PCT, VAL_PCT, TEST_PCT)
    print("Done. Final folder layout under", DEST_ROOT)

import os
import json
import numpy as np
from math import ceil
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.utils.class_weight import compute_class_weight

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# --------------------
# 1. Parameters
# --------------------
IMG_SIZE = (300, 300)  # Bigger input for B3
BATCH_SIZE = 32
EPOCHS_HEAD = 10
EPOCHS_FINE = 20

# Path to dataset
train_dir = "unzipped_data/PlantVillage"  # adjust if needed
val_split = 0.2

# --------------------
# 2. Load Dataset
# --------------------
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split=val_split,
    subset="training",
    seed=123,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split=val_split,
    subset="validation",
    seed=123,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE
)

num_classes = len(train_ds.class_names)
print("Classes:", train_ds.class_names)

# Optimize pipeline
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

# --------------------
# 3. Data Augmentation
# --------------------
data_augmentation = models.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomBrightness(0.1)
])

# --------------------
# 4. Build Model (EfficientNetB3)
# --------------------
base_model = tf.keras.applications.EfficientNetB3(
    include_top=False,
    weights="imagenet",
    input_shape=IMG_SIZE + (3,)
)

base_model.trainable = False  # freeze initially

inputs = tf.keras.Input(shape=IMG_SIZE + (3,))
x = data_augmentation(inputs)
x = tf.keras.applications.efficientnet.preprocess_input(x)  # normalize as per EfficientNet
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.4)(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)

model = models.Model(inputs, outputs)

model.summary()

# --------------------
# 5. Compile & Train Head
# --------------------
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD)

# --------------------
# 6. Fine-Tuning
# --------------------
base_model.trainable = True

# Freeze only first ~200 layers (low-level features)
for layer in base_model.layers[:200]:
    layer.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),  # very small LR for fine-tuning
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history_fine = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FINE)

# --------------------
# 7. Plot Training Curves
# --------------------
def plot_curves(history, fine_tune_history):
    acc = history.history['accuracy'] + fine_tune_history.history['accuracy']
    val_acc = history.history['val_accuracy'] + fine_tune_history.history['val_accuracy']
    loss = history.history['loss'] + fine_tune_history.history['loss']
    val_loss = history.history['val_loss'] + fine_tune_history.history['val_loss']

    epochs_range = range(len(acc))

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label="Train Acc")
    plt.plot(epochs_range, val_acc, label="Val Acc")
    plt.legend()
    plt.title("Accuracy")

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label="Train Loss")
    plt.plot(epochs_range, val_loss, label="Val Loss")
    plt.legend()
    plt.title("Loss")

    plt.show()

plot_curves(history, history_fine)

# --------------------
# 8. Save Model
# --------------------
model.save("plant_disease_model_effnetb3.keras")

train_ds = tf.keras.utils.image_dataset_from_directory(
    "unzipped_data/PlantVillage",
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(300, 300),   # ✅ match EfficientNetB3 input
    batch_size=32
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    "unzipped_data/PlantVillage",
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(300, 300),   # ✅ same here
    batch_size=32
)

# Save class names
class_names = train_ds.class_names

# Prefetch
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images, verbose=0)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

print("Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2

def get_img_array(img_path, size):
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)
    array = tf.keras.preprocessing.image.img_to_array(img)
    array = np.expand_dims(array, axis=0)
    return array

def make_gradcam_heatmap(img_array, efficientnet_model, pred_index=None):
    """
    Generates Grad-CAM heatmap for EfficientNetB3 model directly.
    """
    # Get last conv layer inside EfficientNet
    last_conv_layer = efficientnet_model.get_layer("top_conv")

    grad_model = tf.keras.models.Model(
        inputs=efficientnet_model.input,
        outputs=[last_conv_layer.output, efficientnet_model.output]
    )

    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)

    with tf.GradientTape() as tape:
        last_conv_output, preds = grad_model(img_tensor, training=False)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    grads = tape.gradient(class_channel, last_conv_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    last_conv_output = last_conv_output[0]
    heatmap = last_conv_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def display_gradcam(img_path, model, class_names, size=(300,300)):
    # Load image
    img_array = get_img_array(img_path, size)

    # Access internal EfficientNetB3 layer
    efficientnet_layer = model.get_layer("efficientnetb3")

    # Predict class
    preds = model.predict(img_array)
    pred_class = np.argmax(preds[0])
    print(f"Predicted: {class_names[pred_class]} ({100*np.max(preds[0]):.2f}%)")

    # Grad-CAM heatmap using the internal EfficientNet
    heatmap = make_gradcam_heatmap(img_array, efficientnet_layer, pred_index=pred_class)

    # Load original image
    img = cv2.imread(img_path)
    img = cv2.resize(img, size)

    # Resize and convert heatmap
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

    # Overlay
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Plot
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title("Original Image")
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))
    plt.title("Grad-CAM")
    plt.axis("off")
    plt.show()

# Example usage in Colab:
from google.colab import files

uploaded = files.upload()
img_path = list(uploaded.keys())[0]

# Replace `class_names` with your list of class labels
display_gradcam(img_path, model, class_names, size=(300,300))

model.summary()

